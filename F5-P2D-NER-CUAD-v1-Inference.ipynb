{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper 2 Data Workflow for Data Extraction - CUADv1 - Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sources of information, code and discussions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. The foundation workflow is from Hugging Face's Token Classification example hosted on Colab [here][1]\n",
    "2. The models are base models, each trained using a downstream token clasification task, example [here][2]\n",
    "\n",
    "[1]: https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/token_classification.ipynb\n",
    "[2]: https://huggingface.co/roberta-base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, math, random, json, string, csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForTokenClassification, PreTrainedModel, RobertaTokenizerFast\n",
    "\n",
    "from datasets import load_dataset, ClassLabel, Sequence \n",
    "\n",
    "import fitz # pip install PyMuPDF - PDF reader/parser\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# Resolve any conflicting libraries\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face model references for Transformer library\n",
    "models = dict(\n",
    "    ROBERTA = \"roberta-base\", # Use for efficiency\n",
    "    DEBERTA_V2_XL = \"microsoft/deberta-v2-xlarge\") # Use for accuracy\n",
    "\n",
    "# RANDOM SEED FOR REPRODUCIBILITY\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# BATCH SIZE\n",
    "# IDEALLY USE SAME BATCH SIZE FOR INFERENCE AS WAS USED FOR TRAINING\n",
    "BATCH_SIZES = 2\n",
    "\n",
    "# WHICH PRE-TRAINED TRANSFORMER TO FINE-TUNE?\n",
    "MODEL_CHECKPOINT = models['ROBERTA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1: File and dataset handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_CLASS_LABELS = \"feature_class_labels.json\"\n",
    "TEMP_MODEL_OUTPUT_DIR = 'temp_model_output_dir'\n",
    "SAVED_MODEL = f\"p2d-NER-Fine-Tune-Transformer-Final-{MODEL_CHECKPOINT}\" # Change for notebook version\n",
    "TEST_FILE_PATH = \"./Test_Docs/\"\n",
    "TEST_DATA_FILE = 'test_data_file.json'\n",
    "CSV_DATA_FILE = 'Extracted_Data/legal_agreement_data_file.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 5 legal agreements from ./Test_Docs/ folder:  ['5P 2020-12-15 H665 OOFFS_657.pdf', '3P 06_11_2020-EX-10.1-JVA.PDF', '2P 05_04_2020-EX-10.3.PDF', '1P 04_24_1998-WFS.PDF', '4P 060427_WELLSFARGO_MBS_TRUST_YEA.PDF']\n"
     ]
    }
   ],
   "source": [
    "# Walk through PDF files and create a dataframe with the names of the files, sorted alpha/num\n",
    "pdf_files = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(TEST_FILE_PATH):\n",
    "    pdf_files.extend(filenames)\n",
    "# Remove any hidden files lurking in the directory\n",
    "for i, f in enumerate(pdf_files):\n",
    "    if f.startswith(\".\"):\n",
    "        pdf_files.pop(i)\n",
    "print(f\"Uploaded {len(pdf_files)} legal agreements from {TEST_FILE_PATH} folder: \", pdf_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2: Pre-processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning function for standard PDF parsing workflow\n",
    "def pre_process_doc_common(text):\n",
    "    text = text.replace(\"\\n\", \" \")  # Simple replacement for \"\\n\"   \n",
    "    text = text.replace(\"\\xa0\", \" \")  # Simple replacement for \"\\xa0\"\n",
    "    text = text.replace(\"\\x0c\", \" \")  # Simple replacement for \"\\x0c\"\n",
    "    \n",
    "    regex = \"\\ \\.\\ \"\n",
    "    subst = \".\"\n",
    "    text = re.sub(regex, subst, text, 0)  # Get rid of multiple dots\n",
    "        \n",
    "    regex = \"_\"\n",
    "    subst = \" \"\n",
    "    text = re.sub(regex, subst, text, 0)  # Get rid of underscores\n",
    "       \n",
    "    regex = \"--+\"\n",
    "    subst = \" \"\n",
    "    text = re.sub(regex, subst, text, 0)   # Get rid of multiple dashes\n",
    "        \n",
    "    regex = \"\\*+\"\n",
    "    subst = \"*\"\n",
    "    text = re.sub(regex, subst, text, 0)  # Get rid of multiple stars\n",
    "        \n",
    "    regex = \"\\ +\"\n",
    "    subst = \" \"\n",
    "    text = re.sub(regex, subst, text, 0)  # Get rid of multiple whitespace\n",
    "    \n",
    "    text = text.strip()  #Strip leading and trailing whitespace\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to take in the file list, read each file, clean the text and return all agreements in a list\n",
    "def text_data(test_dir, pdf_files, print_text=False, clean_text=True, max_len=3000):\n",
    "    text_list = []\n",
    "    for filename in tqdm(pdf_files):\n",
    "        agreement = fitz.open(test_dir+filename)\n",
    "        full_text = \"\"\n",
    "        for page in agreement:\n",
    "            full_text += page.getText('text')#+\"\\n\"\n",
    "        if print_text:\n",
    "            print(\"Text before cleaning: \\n\", full_text)\n",
    "\n",
    "        # Run text through cleansing function\n",
    "        if clean_text:\n",
    "            full_text = pre_process_doc_common(full_text)\n",
    "        short_text = full_text[:max_len]\n",
    "        len_text = len(short_text)\n",
    "\n",
    "        if print_text:\n",
    "            print(\"Text after cleaning: \\n\", short_text)\n",
    "\n",
    "        text_list.append([filename, full_text, short_text, len_text])\n",
    "        \n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 71.98it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run reading and cleaning functions on the list of PDF files in the testing folder\n",
    "# Use a max_length which is expected to capture the rich text information at the beginning of the document\n",
    "test_dir = TEST_FILE_PATH\n",
    "data = text_data(test_dir, pdf_files, print_text=False, clean_text=True, max_len=1000)\n",
    "\n",
    "# Create dataframe with text\n",
    "columns = ['File_Name','Full_Text', 'Short_Text', 'Length_Of_Short_Text']\n",
    "text_df = pd.DataFrame(data=data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Full_Text</th>\n",
       "      <th>Short_Text</th>\n",
       "      <th>Length_Of_Short_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5P 2020-12-15 H665 OOFFS_657.pdf</td>\n",
       "      <td>DATED 4 DECEMBER 2020 INVESTOR LIMITED and INV...</td>\n",
       "      <td>DATED 4 DECEMBER 2020 INVESTOR LIMITED and INV...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3P 06_11_2020-EX-10.1-JVA.PDF</td>\n",
       "      <td>Exhibit 10.1 JOINT VENTURE AGREEMENT THIS JOIN...</td>\n",
       "      <td>Exhibit 10.1 JOINT VENTURE AGREEMENT THIS JOIN...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2P 05_04_2020-EX-10.3.PDF</td>\n",
       "      <td>Ex 10.3 SERVICING AGREEMENT between CURO RECEI...</td>\n",
       "      <td>Ex 10.3 SERVICING AGREEMENT between CURO RECEI...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1P 04_24_1998-WFS.PDF</td>\n",
       "      <td>1 EXHIBIT 10.14 OUTSOURCING AGREEMENT This Out...</td>\n",
       "      <td>1 EXHIBIT 10.14 OUTSOURCING AGREEMENT This Out...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4P 060427_WELLSFARGO_MBS_TRUST_YEA.PDF</td>\n",
       "      <td>EXHIBIT 10.3 Yield Maintenance Agreement [LOGO...</td>\n",
       "      <td>EXHIBIT 10.3 Yield Maintenance Agreement [LOGO...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                File_Name  \\\n",
       "0        5P 2020-12-15 H665 OOFFS_657.pdf   \n",
       "1           3P 06_11_2020-EX-10.1-JVA.PDF   \n",
       "2               2P 05_04_2020-EX-10.3.PDF   \n",
       "3                   1P 04_24_1998-WFS.PDF   \n",
       "4  4P 060427_WELLSFARGO_MBS_TRUST_YEA.PDF   \n",
       "\n",
       "                                           Full_Text  \\\n",
       "0  DATED 4 DECEMBER 2020 INVESTOR LIMITED and INV...   \n",
       "1  Exhibit 10.1 JOINT VENTURE AGREEMENT THIS JOIN...   \n",
       "2  Ex 10.3 SERVICING AGREEMENT between CURO RECEI...   \n",
       "3  1 EXHIBIT 10.14 OUTSOURCING AGREEMENT This Out...   \n",
       "4  EXHIBIT 10.3 Yield Maintenance Agreement [LOGO...   \n",
       "\n",
       "                                          Short_Text  Length_Of_Short_Text  \n",
       "0  DATED 4 DECEMBER 2020 INVESTOR LIMITED and INV...                  1000  \n",
       "1  Exhibit 10.1 JOINT VENTURE AGREEMENT THIS JOIN...                  1000  \n",
       "2  Ex 10.3 SERVICING AGREEMENT between CURO RECEI...                  1000  \n",
       "3  1 EXHIBIT 10.14 OUTSOURCING AGREEMENT This Out...                  1000  \n",
       "4  EXHIBIT 10.3 Yield Maintenance Agreement [LOGO...                  1000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look at the unstructured data captured so far\n",
    "text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"DATED 4 DECEMBER 2020 INVESTOR LIMITED and INVESTMENT LIMITED OPTION AGREEMENT FOR FUTURE SHARES THIS AGREEMENT is made and entered into on 4 December 2020 BETWEEN (1) INVESTOR LIMITED a company incorporated in Jersey with registration number 123456 and whose registered office is at King Street, Jersey, Channel Islands, JE2 2EJ (the ‚ÄúInvestor‚Äù); and (2) INVESTMENT LIMITED a company incorporated in Jersey with registration number 654321 and whose registered office is at Queen Street, Jersey, JE2 2EJ, Channel Islands, Great Britain with an email address of investment@greatinvestments.com (the ‚ÄúCompany‚Äù). WHEREAS (A) The Company was incorporated on 1 January 2020 and has at the date of this Agreement an authorised share capital of 10,000,000 divided into 10,000,000 registered shares of ¬£1.00 each and an issued share capital of 10,000 shares of ¬£1.00 each. (B) The Investor wishes to pay the Investment into the Company pursuant to the terms of this Agreement. The Investment shall automatically convert into fully paid Shares at the Conversion Rate on the occurrence of a Conversion Event on the terms of this Agreement. (C) The Investment is made subject to the disclaimer contained in the Schedule. OPERATIVE PROVISIONS 1 Definitions 1.1 The definitions and rules of interpretation in this clause apply in this Agreement: 1.1.1 Change of Control: occurs if a person who Controls any body corporate ceases to do so or if another person acquires Control of it. 1.1.2 Control: in relation to a body corporate, the power of a person to secure that the affairs of the body corporate are conducted in accordance with the wishes of that person: (a) as a result of any powers conferred by the articles of association or any other document regulating that or any other body corporate; or (b) by means of the holding of shares, or the possession of voting power, in or in relation to that or any other body corporate. 1.1.3 Conversion Date: the date of the conversion of the Investment into the Conversion Shares; 1.1.4 Conversion Events: the events specified in clause 4.1; 1.1.5 Conversion Notice: a notice in writing by the Investor to the Company to convert all of the outstanding Investment into Conversion Shares; 1.1.6 Conversion Price: means either: (a) that number of Conversion Shares that equate to 15% of the entire issued share capital of the Company immediately prior to the Fund Raise taking place; or (b) the Discount Price, whichever calculation results in a greater number of Conversion Shares (with any fraction of a share being rounded up to a full share); 1.1.7 Conversion Rate: (a) subject to clause 1.1.6(b) the conversion of the Investment into such number of Conversion Shares which represent a total of 15% of the entire issued share capital of the Company at that time (with any fraction of a share being rounded up to a full share); or (b) in the case of a Fund Raising specified in clause 4.1.1, the Investment shall convert into such number of Conversion Shares at the Conversion Price; 1.1.8 Conversion Shares: such number of new Shares credited as fully paid converted at the Conversion Rate into share capital on the Conversion Date. 1.1.9 Discount Price: the price per share of the Shares sold in the Fund Raising multiplied by the Discount Rate; 1.1.10 Discount Rate: 85%; 1.1.11 Fund Raising: the Company raising a total of ¬£200,000,000 or more prior to the second anniversary of this Agreement from an issue of Shares to any person(s) (and excluding, for the avoidance of doubt, the Investment to be converted into Shares); 1.1.12 Investment: the sum of ¬£500,000 to be invested into the Company as a convertible debt; and 1.1.13 Shares: the ordinary shares of ¬£1.00 par value in the capital of the Company. 2 The Investment The Investor shall pay the Investment to the Company on the date of this Agreement, or latest close of business Friday, 20 November 2020, to the Company‚Äôs nominated bank account. The Investment shall be used to the purpose of developing the Company‚Äôs business in accordance with its business plan. 3 Investment Terms 3.1 The Investment shall not bear interest, shall be interest free and shall be unsecured. 3.2 Subject to any conversion into Conversion Shares pursuant to the terms of this Agreement, the Investment shall be repayable on the tenth anniversary of the date of this Agreement (or such other date as the parties shall agree in writing). 4 Share Conversion 4.1 The Investment shall automatically convert into Conversion Shares at the Conversion Rate on the earlier of the following events: 4.1.1 upon the Fund Raising; or 4.1.2 pursuant to the issuance of a Conversion Notice in accordance with clause 5.1; or 4.1.3 pursuant to the conversion of the Investment into Conversion Shares pursuant to clause 5.2; or 4.1.4 upon a Change of Control. 4.2 In the event that there is a Fund Raising pursuant to clause 4.1.1, on the initial closing of such Fund Raising, the Investment will automatically convert into the number of Shares equal to the Conversion Price. 5 Conversion Option 5.1 At any time following the second anniversary of this Agreement, the Investor shall have the right to serve a Conversion Notice on the Company to convert all of the Investment outstanding into the Conversion Shares at the Conversion Rate. Once served the Conversion Notice shall be irrevocable. 5.2 At any time following the second anniversary of this Agreement, the Company shall have the right to convert the Investment into the Conversion Shares at the Conversion Rate by providing notice in writing to the Investor pursuant to clause 6.1. 6 Investor Notice 6.1 If and when a Conversion Event specified in clause 4.1.1 , 4.1.4 or 5.2 is proposed, the Company shall give the Investor not less than 30 business days' prior written notice of the proposed Conversion Event specifying (to the best of its knowledge) the terms and prospective date of the Conversion Event. 6.2 If the Company has given notice to the Investor of a proposed Conversion Event (specified in clause 4.1.1 or 4.1.4 or 5.2), and it becomes apparent to the Company that the Conversion Event is not after all to take effect, the Company shall promptly give notice to the Investor to that effect and the conversion will not take place. 6.3 If the Investor gives a Conversion Notice to the Company in accordance with this clause 6, the Company shall within 14 Business Days of receipt of the Conversion Notice give to the Investor notice of the Conversion Date which will be a date that falls between 30 and 60 Business Days after the Company receives the Conversion Notice. 7 Conversion Shares 7.1 On the Conversion Date, the Directors shall convert the principal amount of the Investment into the Conversion Shares. 7.2 On the Conversion Date the Investor shall be deemed to irrevocably authorise and instruct the Company to apply the Investment moneys payable to the Investor in subscribing for Shares on conversion of the Investment. 7.3 Upon the issue of the Conversion Shares to the Investor, the Investor will irrevocably waive all and any rights in relation to the Investment. The Conversion Shares arising on conversion of the Investment shall be credited as fully paid and rank pari passu with Shares (of the same class) in issue on the Conversion Date and shall carry the right to receive all dividends and other distributions declared after the Conversion Date. 7.4 The Company agrees to issue the Conversion Shares to the Investor free from all and any security interests, liens, charges and other encumbrances and with all accrued rights and benefits attaching thereto at Completion. 7.5 The Company undertakes that, prior to the Conversion Date, it shall: 7.5.1 not alter the Articles in any way which would adversely affect the rights of the Investor without the prior sanction of a Special Resolution; and 7.5.2 maintain sufficient shareholder authority to satisfy in full the most onerous of the outstanding rights of conversion for the time being attaching to the Investment. 8 Completion 8.1 On the Conversion Date, the Company shall issue the Conversion Shares to the Investor and shall procure that: 8.1.1 the Investor is registered as the holder of the Conversion Shares in the Company‚Äôs register of members; and 8.1.2 the Investor is provided with the relevant share certificates to evidence its ownership of the Conversion Shares. 9 Representations and Warranties 9.1 Both the Company and the Investor have the right, power and authority and have taken all actions necessary to execute and to exercise their rights and perform their obligations under this Agreement. 9.2 This Agreement has been duly executed by each of the Company and the Investor and constitutes legally valid and binding obligations of each of the Company and the Investor, enforceable against it except to the extent that such enforceability may be limited by bankruptcy, insolvency, reorganisation and other similar laws relating to or limiting creditors' rights generally. 9.3 In order to induce the Investor to enter into this Agreement and to advance the Investment hereunder, the Company represents and warrants to the Investor as at the date to this Agreement: 9.3.1 the execution, delivery and performance of this Agreement will not result in any breach of or default under any other agreement or instrument to which the Company is a party or is subject which would have a material adverse effect to its business or financial condition; and 9.3.2 no litigation or proceeding is instituted, pending, or to the Company's knowledge, threatened against it or any of its assets. 10 Costs and Expenses 10.1 The Company shall pay for all costs and expenses (including without limitation, legal fees) incurred in connection with the preparation, execution and enforcement of this Agreement, associated costs relating to the registration of trademarks, intellectual property and the completion of the transactions herein contemplated. The costs referred to in this clause to the Company will be redeemed pro-rata from initial funding raising and will be accounted for through the books and records of the Company. 11 Benefit of Agreement This Agreement shall be binding upon and inure to the benefit of each party to the Agreement and each party's successors and, where applicable, permitted assigns. 12 Assignment The parties shall not be entitled to assign or transfer all or any of its rights, benefits and obligations hereunder without the consent of the other party. 13 General 13.1 This Agreement shall, to the extent that it remains to be performed, continue in full force and effect after Completion. 13.2 This Agreement and any dispute or claim arising out of or in connection with it or its subject matter, whether of a contractual or non-contractual nature, shall be governed by and construed in accordance with the law of Jersey. 13.3 The parties irrevocably agree that the courts of Jersey shall have exclusive jurisdiction to settle any dispute which may arise out of or in connection with this Agreement. 13.4 Any notice required or permitted by this Agreement will be deemed sufficient when delivered personally or by overnight courier or sent by email to the relevant address herein, or 48 hours after being posted as certified or registered mail, addressed to the party to be notified at such party‚Äôs address listed herein, as subsequently modified by written notice. 13.5 In the event of any dispute between the terms of this Agreement and the provisions of the Company‚Äôs Articles of Association, the Articles of Association shall take prevail. 13.6 The parties shall not make any other public announcement or issue any other press release or respond to any enquiry from the press or other media concerning or relating to this Agreement or its subject matter or any ancillary matter except if, and to the extent, required by law or governmental, regulatory or other authority. 13.7 Each party shall keep confidential the existence and terms of this Agreement and all information received or obtained as a result of negotiating, preparing, executing, performing or implementing it which relates to the other party or any agent or subcontractor acting on its behalf. Neither party shall use such information for any purpose other than to perform its obligations under this Agreement. Notwithstanding the foregoing, either party may, after consultation with the other party whenever practicable, disclose confidential information if and to the extent: 13.7.1 required by law; or 13.7.2 required by any securities exchange on which either party‚Äôs securities are listed or traded; or 13.7.3 required by any regulatory or governmental or other authority with relevant powers to which either party is subject or submits (whether or not the authority has the force of law); or 13.7.4 required to vest the full benefit of this Agreement in that party or to enforce any of the rights of that party in this Agreement; or 13.7.5 required by its professional advisers, officers, employees, consultants, subcontractors or agents to provide their services (and subject always to similar duties of confidentiality); or 13.7.6 that information is in or has come into the public domain through no fault of that party; or 13.7.7 the other party has given prior written consent to the disclosure; or 13.7.8 it is necessary to obtain any relevant tax clearances from any appropriate tax authority. The provisions of this clause 13.7 shall supersede and extinguish any other agreement between the parties relating to the subject matter of this clause 13.7 and shall continue to apply for 10 years after and Completion of this Agreement. 13.8 This Agreement contains the entire agreement between the parties with respect to its subject matter. Each of the parties acknowledges and agrees that it has not entered into this Agreement in reliance on any statement or representation of any person (whether a party to this Agreement or not) other than as expressly incorporated in this Agreement. Each of the parties irrevocably and unconditionally waives any right or remedy it may have to claim damages and/or to rescind this Agreement by reason of any misrepresentation (other than a fraudulent misrepresentation) not contained in this Agreement. 13.9 This Agreement may be executed in any number of counterparts, each of which shall constitute an original, and all the counterparts shall together constitute one and the same Agreement. SCHEDULE Important Information This document is confidential. Information herein is solely intended for the specified recipient and is not for redistribution. Although the information provided in the Documentation and conversations with the Investor were based on good faith and extensive research undertaken by the Company, no representation or warranty, express or implied, is made as to its accuracy or completeness. All information and opinions are subject to change without notice. Tax treatment of the Investor‚Äôs investment will depend on the Investor‚Äôs personal and individual circumstances and the Investor should engage their own professional legal, tax and accountancy advisors to inform of any implications of this Investment. The Company is not liable for any tax events in relation to the Investment. THE PARTIES below have executed this Agreement on the date written above. SIGNED BY the following authorised signatories on behalf of INVESTOR LIMITED ‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶. Authorised Signatory SIGNED BY the following authorised signatory on behalf of INVESTMENT LIMITED ‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶. Authorised Signatory\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does an agreement look like?\n",
    "text_df['Full_Text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3: Tokenization and feature labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-3b8ec555e7e2a434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /Users/philgodley/.cache/huggingface/datasets/json/default-3b8ec555e7e2a434/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /Users/philgodley/.cache/huggingface/datasets/json/default-3b8ec555e7e2a434/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02. Subsequent calls will reuse this data.\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['split_tokens', 'dummy_ner_tags'],\n",
      "        num_rows: 5\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# We tokenize each agreement prior to bringing into the transformer model\n",
    "# Create tokens using spaCy\n",
    "nlp = English()\n",
    "text_df['tokens'] = text_df['Short_Text'].apply(lambda x: nlp(x))\n",
    "\n",
    "# Split tokens into a list ready for CSV\n",
    "text_df['split_tokens'] = text_df['tokens'].apply(lambda x: [tok.text for tok in x])\n",
    "\n",
    "# Create dummy NER tags for alignment purposes (a bit lazy, but convinient)\n",
    "text_df['dummy_ner_tags'] = text_df['tokens'].apply(lambda x: [0 for tok in x])\n",
    "\n",
    "# Serialise the data to JSON for archive\n",
    "export_columns = ['split_tokens', 'dummy_ner_tags']\n",
    "export_df = text_df[export_columns]\n",
    "export_df.to_json(TEST_DATA_FILE, orient=\"table\", index=False)\n",
    "text_df = text_df.drop(['dummy_ner_tags'], axis=1)\n",
    "\n",
    "# Re-import the serialized JSON data and create a dataset in the format needed for the transformer\n",
    "data_files = TEST_DATA_FILE\n",
    "datasets = load_dataset('json', data_files=data_files, field='data')\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 B-AGMT_DATE\n",
      "1 B-DOC_NAME\n",
      "2 B-PARTY\n",
      "3 I-AGMT_DATE\n",
      "4 I-DOC_NAME\n",
      "5 I-PARTY\n",
      "6 O\n"
     ]
    }
   ],
   "source": [
    "# Open the label list created in pre-processing corresponding to the ner_tag indices\n",
    "with open(FEATURE_CLASS_LABELS, 'r') as f:\n",
    "    label_list = json.load(f)\n",
    "\n",
    "for n in range(len(label_list)):\n",
    "    print(n, label_list[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the tokenizer\n",
    "#For RoBERTa-base, need to use RobertaTokenizerFast with add_prefix_space=True to use it with pretokenized inputs.\n",
    "\n",
    "if MODEL_CHECKPOINT == models['ROBERTA']:\n",
    "    tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\", add_prefix_space=True)\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions deal with split tokens and special tokens used in each Transformer model\n",
    "def word_id_func(input_ids, print_labs=False):\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    \n",
    "    word_ids = []\n",
    "    i=0\n",
    "    spec_toks = ['[CLS]', '[SEP]', '[PAD]']\n",
    "    for t in tokens:\n",
    "        if t in spec_toks:\n",
    "            word_ids.append(-100)\n",
    "            print(t, i) if print_labs else None\n",
    "        elif t.startswith('‚ñÅ'):\n",
    "            i += 1\n",
    "            word_ids.append(i)\n",
    "            print(t, i) if print_labs else None\n",
    "        else:\n",
    "            word_ids.append(i)\n",
    "            print(t, i) if print_labs else None\n",
    "        print(\"Total:\", i) if print_labs else None\n",
    "    return word_ids\n",
    "\n",
    "def tokenize_and_align_labels(examples, label_all_tokens=False):\n",
    "    tokenized_inputs = tokenizer(examples[\"split_tokens\"],\n",
    "                                 truncation=True,\n",
    "                                 is_split_into_words=True)\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"dummy_ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "def tokenize_and_align_labels_deberta(examples, label_all_tokens=False):\n",
    "    tokenized_inputs = tokenizer(examples[\"split_tokens\"],\n",
    "                                 truncation=True,\n",
    "                                 is_split_into_words=True)\n",
    "    labels = []\n",
    "    word_ids_list = []\n",
    "    for input_ids in tokenized_inputs[\"input_ids\"]:\n",
    "        wids = word_id_func(input_ids, print_labs=False)\n",
    "        word_ids_list.append(wids)\n",
    "    \n",
    "    for i, label in enumerate(examples[\"dummy_ner_tags\"]):\n",
    "        word_ids = word_ids_list[i]\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx == -100:\n",
    "                label_ids.append(-100)\n",
    "            #We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx-1])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label[word_idx-1] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762dd01c4c634dd183f7fd2b1f261513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To apply this function on all the words and labels in our dataset,\n",
    "# we just use the map method of our dataset object we created earlier.\n",
    "\n",
    "# ü§ó Datasets warns you when it uses cached files, you can pass load_from_cache_file=False in the\n",
    "# call to map to not use the cached files and force the preprocessing to be applied again.\n",
    "if MODEL_CHECKPOINT == models['DEBERTA_V2_XL']:\n",
    "    tokenize_and_align_labels = tokenize_and_align_labels_deberta\n",
    "\n",
    "tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True, load_from_cache_file=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Predictions and Inference\n",
    "\n",
    "Now to run the trained and serialised model on the evaluation set again, NOT the data used for training.\n",
    "\n",
    "Always take care to ensure that there isn't any data leakage here, eg the same agreements, different agreements from the same set of agreement or potentially different agreements from the same parties. \n",
    "\n",
    "The objective is to ensure that the model is able to generalize well to new agreements never seen before.\n",
    "\n",
    "To match the number of predictions to the original numnber of tokens, need to use: \"label_all_tokens=False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and instantiate\n",
    "loaded_model = AutoModelForTokenClassification.from_pretrained(SAVED_MODEL)\n",
    "\n",
    "args = TrainingArguments(output_dir = TEMP_MODEL_OUTPUT_DIR,\n",
    "                         per_device_train_batch_size=BATCH_SIZES,\n",
    "                         per_device_eval_batch_size=BATCH_SIZES,\n",
    "                         seed=RANDOM_SEED\n",
    "                        )\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "# Note instantiation currently takes a bit of time: https://github.com/huggingface/transformers/issues/9205\n",
    "# Instantiate the predictor\n",
    "pred_trainer = Trainer(\n",
    "    loaded_model,\n",
    "    args,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>true_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5P 2020-12-15 H665 OOFFS_657.pdf</td>\n",
       "      <td>[B-AGMT_DATE, B-AGMT_DATE, I-AGMT_DATE, I-AGMT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3P 06_11_2020-EX-10.1-JVA.PDF</td>\n",
       "      <td>[O, O, B-DOC_NAME, I-DOC_NAME, I-DOC_NAME, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2P 05_04_2020-EX-10.3.PDF</td>\n",
       "      <td>[O, O, B-DOC_NAME, I-DOC_NAME, O, B-PARTY, I-P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1P 04_24_1998-WFS.PDF</td>\n",
       "      <td>[O, O, O, B-DOC_NAME, I-DOC_NAME, O, B-DOC_NAM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4P 060427_WELLSFARGO_MBS_TRUST_YEA.PDF</td>\n",
       "      <td>[O, O, B-DOC_NAME, I-DOC_NAME, I-DOC_NAME, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                File_Name  \\\n",
       "0        5P 2020-12-15 H665 OOFFS_657.pdf   \n",
       "1           3P 06_11_2020-EX-10.1-JVA.PDF   \n",
       "2               2P 05_04_2020-EX-10.3.PDF   \n",
       "3                   1P 04_24_1998-WFS.PDF   \n",
       "4  4P 060427_WELLSFARGO_MBS_TRUST_YEA.PDF   \n",
       "\n",
       "                                    true_predictions  \n",
       "0  [B-AGMT_DATE, B-AGMT_DATE, I-AGMT_DATE, I-AGMT...  \n",
       "1  [O, O, B-DOC_NAME, I-DOC_NAME, I-DOC_NAME, O, ...  \n",
       "2  [O, O, B-DOC_NAME, I-DOC_NAME, O, B-PARTY, I-P...  \n",
       "3  [O, O, O, B-DOC_NAME, I-DOC_NAME, O, B-DOC_NAM...  \n",
       "4  [O, O, B-DOC_NAME, I-DOC_NAME, I-DOC_NAME, O, ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the predictions\n",
    "predictions, labels, _ = pred_trainer.predict(tokenized_datasets[\"train\"])\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "text_df['predictions'] = list(predictions)\n",
    "\n",
    "# Remove ignored index (special tokens)\n",
    "true_predictions = [\n",
    "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "text_df['true_predictions'] = true_predictions\n",
    "\n",
    "# Consolidate all the information into the DataFrame\n",
    "def data_extract(tuple_list):\n",
    "    de_list = []\n",
    "    for tup in tuple_list:\n",
    "        if tup[1] != 'O':\n",
    "            de_list.append(tup)\n",
    "    return de_list\n",
    "\n",
    "text_df['check_pred'] = list(list(zip(a,b)) for a,b in zip(text_df['split_tokens'], text_df['true_predictions']))\n",
    "text_df['data_tuples'] = text_df['check_pred'].apply(data_extract)\n",
    "\n",
    "# Have a look at the label predictions\n",
    "text_df.head()[['File_Name', 'true_predictions']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step5: Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>agmt_name</th>\n",
       "      <th>agmt_date</th>\n",
       "      <th>agmt_parties</th>\n",
       "      <th>Full_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1P 04_24_1998-WFS.PDF</td>\n",
       "      <td>Outsourcing Agreement</td>\n",
       "      <td>January 1 , 1998</td>\n",
       "      <td>[Sykes HealthPlan Services , Inc., HealthPlan ...</td>\n",
       "      <td>1 EXHIBIT 10.14 OUTSOURCING AGREEMENT This Out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2P 05_04_2020-EX-10.3.PDF</td>\n",
       "      <td>SERVICING AGREEMENT</td>\n",
       "      <td>April 8 , 2020 ,</td>\n",
       "      <td>[CURO RECEIVABLES FINANCE II , LLC, CURO MANAG...</td>\n",
       "      <td>Ex 10.3 SERVICING AGREEMENT between CURO RECEI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3P 06_11_2020-EX-10.1-JVA.PDF</td>\n",
       "      <td>JOINT VENTURE AGREEMENT</td>\n",
       "      <td>20th day of Friday , March 2020</td>\n",
       "      <td>[BorrowMoney.com , inc, JVLS , LLC, Vaccines 2Go]</td>\n",
       "      <td>Exhibit 10.1 JOINT VENTURE AGREEMENT THIS JOIN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4P 060427_WELLSFARGO_MBS_TRUST_YEA.PDF</td>\n",
       "      <td>Yield Maintenance Agreement</td>\n",
       "      <td>27 April 2006</td>\n",
       "      <td>[Wells Fargo Bank , N.A., Wells Fargo Mortgage...</td>\n",
       "      <td>EXHIBIT 10.3 Yield Maintenance Agreement [LOGO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5P 2020-12-15 H665 OOFFS_657.pdf</td>\n",
       "      <td>OPTION AGREEMENT FOR FUTURE SHARES</td>\n",
       "      <td>4 December 2020</td>\n",
       "      <td>[INVESTOR LIMITED, INVESTMENT LIMITED]</td>\n",
       "      <td>DATED 4 DECEMBER 2020 INVESTOR LIMITED and INV...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                File_Name                           agmt_name  \\\n",
       "3                   1P 04_24_1998-WFS.PDF               Outsourcing Agreement   \n",
       "2               2P 05_04_2020-EX-10.3.PDF                 SERVICING AGREEMENT   \n",
       "1           3P 06_11_2020-EX-10.1-JVA.PDF             JOINT VENTURE AGREEMENT   \n",
       "4  4P 060427_WELLSFARGO_MBS_TRUST_YEA.PDF         Yield Maintenance Agreement   \n",
       "0        5P 2020-12-15 H665 OOFFS_657.pdf  OPTION AGREEMENT FOR FUTURE SHARES   \n",
       "\n",
       "                         agmt_date  \\\n",
       "3                 January 1 , 1998   \n",
       "2                 April 8 , 2020 ,   \n",
       "1  20th day of Friday , March 2020   \n",
       "4                    27 April 2006   \n",
       "0                  4 December 2020   \n",
       "\n",
       "                                        agmt_parties  \\\n",
       "3  [Sykes HealthPlan Services , Inc., HealthPlan ...   \n",
       "2  [CURO RECEIVABLES FINANCE II , LLC, CURO MANAG...   \n",
       "1  [BorrowMoney.com , inc, JVLS , LLC, Vaccines 2Go]   \n",
       "4  [Wells Fargo Bank , N.A., Wells Fargo Mortgage...   \n",
       "0             [INVESTOR LIMITED, INVESTMENT LIMITED]   \n",
       "\n",
       "                                           Full_Text  \n",
       "3  1 EXHIBIT 10.14 OUTSOURCING AGREEMENT This Out...  \n",
       "2  Ex 10.3 SERVICING AGREEMENT between CURO RECEI...  \n",
       "1  Exhibit 10.1 JOINT VENTURE AGREEMENT THIS JOIN...  \n",
       "4  EXHIBIT 10.3 Yield Maintenance Agreement [LOGO...  \n",
       "0  DATED 4 DECEMBER 2020 INVESTOR LIMITED and INV...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Functions to extract each important data point based on the model's labeling of each token\n",
    "\n",
    "def extract_agreement_date(tuple_list):\n",
    "    for d in tuple_list:\n",
    "        if d[1] == \"B-AGMT_DATE\":\n",
    "            temp_date=d[0]\n",
    "        elif d[1] == \"I-AGMT_DATE\":\n",
    "            temp_date = temp_date + \" \" + d[0]\n",
    "        else:\n",
    "            continue\n",
    "    return temp_date\n",
    "\n",
    "text_df['agmt_date'] = text_df['data_tuples'].apply(extract_agreement_date)\n",
    "\n",
    "def extract_agreement_name(tuple_list):\n",
    "    for n in tuple_list:\n",
    "        if n[1] == \"B-DOC_NAME\":\n",
    "            temp_name=n[0]\n",
    "        elif n[1] == \"I-DOC_NAME\":\n",
    "            temp_name = temp_name + \" \" + n[0]\n",
    "        else:\n",
    "            continue\n",
    "    return temp_name\n",
    "\n",
    "text_df['agmt_name'] = text_df['data_tuples'].apply(extract_agreement_name)\n",
    "\n",
    "def extract_agreement_parties(tuple_list):\n",
    "    data_dict = defaultdict(list)\n",
    "    for i, p in enumerate(tuple_list):\n",
    "        if p[1] == \"B-PARTY\":\n",
    "            temp_party=p[0]\n",
    "            if i == (len(tuple_list)-1):\n",
    "                data_dict[\"Parties\"].append(temp_party)\n",
    "            elif tuple_list[i+1][1] != \"I-PARTY\":\n",
    "                data_dict[\"Parties\"].append(temp_party)\n",
    "        elif p[1] == \"I-PARTY\":\n",
    "            temp_party = temp_party + \" \" + p[0]\n",
    "            if i == (len(tuple_list)-1):\n",
    "                data_dict[\"Parties\"].append(temp_party)\n",
    "            elif tuple_list[i+1][1] != \"I-PARTY\":\n",
    "                data_dict[\"Parties\"].append(temp_party)\n",
    "\n",
    "    return list(dict.fromkeys(data_dict['Parties']))\n",
    "\n",
    "text_df['agmt_parties'] = text_df['data_tuples'].apply(extract_agreement_parties)\n",
    "\n",
    "# Create a dataframe with just the information we want to keep and \n",
    "export_df = text_df[['File_Name', 'agmt_name', 'agmt_date', 'agmt_parties', 'Full_Text']].copy()\n",
    "export_df = export_df.sort_values('File_Name', axis=0)\n",
    "\n",
    "# Let's have a look\n",
    "export_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Name: \t\t 3P 06_11_2020-EX-10.1-JVA.PDF\n",
      "Agreement Name: \t JOINT VENTURE AGREEMENT\n",
      "Agreement Date: \t 20th day of Friday , March 2020\n",
      "Agreement Parties:\n",
      "\t\t\t BorrowMoney.com , inc\n",
      "\t\t\t JVLS , LLC\n",
      "\t\t\t Vaccines 2Go\n"
     ]
    }
   ],
   "source": [
    "# Example data\n",
    "sample=2\n",
    "print(\"File Name: \\t\\t\",export_df.iloc[sample][0])\n",
    "print(\"Agreement Name: \\t\",export_df.iloc[sample][1])\n",
    "print(\"Agreement Date: \\t\",export_df.iloc[sample][2])\n",
    "print(\"Agreement Parties:\")\n",
    "for p in export_df.iloc[sample][3]:\n",
    "    print(\"\\t\\t\\t\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV file, upload to a database table or some other structured data format, we are done.\n",
    "export_df.to_csv(CSV_DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
